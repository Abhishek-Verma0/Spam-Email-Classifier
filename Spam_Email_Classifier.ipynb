{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing important libs\n",
        "import numpy as np  # Used for numerical operations\n",
        "import pandas as pd  # Used for handling and processing data in tabular format\n",
        "import re  # Regular expressions for text cleaning\n",
        "\n",
        "# Import NLP tools from NLTK\n",
        "from nltk.corpus import stopwords  # To remove common stopwords (e.g., \"is\", \"the\", \"and\")\n",
        "from nltk.stem import WordNetLemmatizer  # To lemmatize words (e.g., \"running\" â†’ \"run\")\n",
        "\n",
        "# Import machine learning and text processing libraries\n",
        "from sklearn.model_selection import train_test_split  # To split the dataset into training and testing sets\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "# CountVectorizer: Converts text into word frequency counts\n",
        "# TfidfTransformer: Converts word counts to TF-IDF scores\n",
        "# TfidfVectorizer: Directly applies TF-IDF transformation in one step\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic Regression model for classification\n",
        "from sklearn.metrics import accuracy_score, classification_report  # Evaluation metrics\n",
        "\n",
        "# Import SMOTE for handling imbalanced datasets\n",
        "from imblearn.over_sampling import SMOTE  # Used to balance dataset by generating synthetic samples for minority class"
      ],
      "metadata": {
        "id": "x1QBuZItWk-9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the  dataset\n",
        "df = pd.read_csv(\"mail_data.csv\")\n",
        "\n",
        "# Handle missing values (replace NaN with an empty string)\n",
        "df = df.where(pd.notnull(df), '')\n",
        "\n",
        "# Convert Category column to binary class where spam = 1, ham = 0\n",
        "df['Category'] = df['Category'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english')) - {'you', 'for', 'it'}  # Keep all  key stopwords\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Converts all text  to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters, but keep numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Removes extra spaces from the text\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply text cleaning to the  messages\n",
        "df['clean_msg'] = df['Message'].apply(clean_text)\n",
        "\n",
        "# Convert text into numerical features using TF-IDF (with bigrams)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "X_tfidf = vectorizer.fit_transform(df['clean_msg'])\n",
        "\n",
        "# Target labels (Spam = 1, Ham = 0)\n",
        "y = df['Category']\n",
        "\n",
        "# Balance dataset using SMOTE (fix spam underrepresentation)\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "\n",
        "# Split data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model using Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q1tJuoB83V7",
        "outputId": "624922a4-2559-4b94-df92-6b128d7c936f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9955958549222798\n",
            "Testing Accuracy: 0.9932642487046632\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       990\n",
            "           1       0.99      0.99      0.99       940\n",
            "\n",
            "    accuracy                           0.99      1930\n",
            "   macro avg       0.99      0.99      0.99      1930\n",
            "weighted avg       0.99      0.99      0.99      1930\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict a new email\n",
        "def predict_email(email):\n",
        "    email_cleaned = clean_text(email)  # Apply same preprocessing\n",
        "    email_tfidf = vectorizer.transform([email_cleaned])  # Convert to TF-IDF\n",
        "    prediction = model.predict(email_tfidf)  # Get prediction\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
        "\n",
        "# Test with a user input email\n",
        "input_mail = input(\"Enter an email to classify: \")\n",
        "print(\"Prediction:\", predict_email(input_mail))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLMN894IAhHJ",
        "outputId": "cac7d7ae-3a0c-4e38-efdd-5abdb4e64f55"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an email to classify: You Have a New Friend Request!Someone is eager to connect with you.It's Time to Connect! Click below to either accept or ignore the friend request from this user. The choice is yours! Accept Request Ignore Request If you didn't make this request feel free to disregard this email\n",
            "Prediction: Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faeq9rVKFnOf"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}